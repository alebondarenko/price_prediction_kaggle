{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def strip_punct(s):\n",
    "    sentences = []\n",
    "    exclude = set(string.punctuation)\n",
    "    exclude.add(']')\n",
    "    exclude.add('[')\n",
    "    exclude.add('\\xad')\n",
    "    exclude.add('\\n')\n",
    "    exclude.add('\\n1')\n",
    "    exclude.add('\\n2')\n",
    "    exclude.add('\\n3')\n",
    "    exclude.add('•')\n",
    "    exclude.add('«')\n",
    "    exclude.add('»')\n",
    "    for i in range(len(s)):\n",
    "        sentences.append(''.join(ch for ch in str(s[i]).lower() if ch not in exclude))\n",
    "    return sentences\n",
    "\n",
    "def vector_prep(l):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    for i in range(len(l)):\n",
    "        l_str = ''\n",
    "        l1.append(re.split(r'[/&]', str(l[i])))\n",
    "        for x in range (len(l1[i])):\n",
    "            l_str += l1[i][x] + ' '\n",
    "        l2.append(' '.join(l_str.strip().split()))\n",
    "    return l2\n",
    "\n",
    "def feature(l1, l2, l3):\n",
    "    feature = []\n",
    "    for i in range(len(l1)):\n",
    "        feature.append(l1[i].lower() + ' ' + l2[i].lower() + ' ' + l3[i].lower())\n",
    "    return feature\n",
    "\n",
    "def cros_val(model, x_train_array, price_train, n_run):\n",
    "    print ('Cross-validation: {}'.format(cross_val_score(model, x_train_array, price_train, cv=n_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Take only part of the training data to work on\n",
    "other, train = train_test_split(df, test_size=0.1)\n",
    "\n",
    "#Split the train into test and train data\n",
    "train, test = train_test_split(train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_name_train = train['category_name'].tolist()\n",
    "name_train = train['name'].tolist()\n",
    "brand_train = train['brand_name'].tolist()\n",
    "price_train = train['price'].tolist()\n",
    "\n",
    "category_name_test = test['category_name'].tolist()\n",
    "name_test = test['name'].tolist()\n",
    "brand_test = test['brand_name'].tolist()\n",
    "price_test = test['price'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_l_train = vector_prep(category_name_train)\n",
    "name_l_train = vector_prep(name_train)\n",
    "brand_l_train = vector_prep(brand_train)\n",
    "\n",
    "category_l_test = vector_prep(category_name_test)\n",
    "name_l_test = vector_prep(name_test)\n",
    "brand_l_test = vector_prep(brand_test)\n",
    "\n",
    "feature_train = feature(category_l_train, name_l_train, brand_l_train)\n",
    "feature_test = feature(category_l_test, name_l_test, brand_l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(feature_train)\n",
    "#x_train_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model_l = model.fit(X, price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_test = ['small cat harness and leash Other Pet Supplies Others']\n",
    "newVec = CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
    "X_test = newVec.fit_transform(feature_test)\n",
    "prices_predicted = model_l.predict(X_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation: [ 0.17107795  0.13800486  0.03985989  0.22915635  0.17793956]\n"
     ]
    }
   ],
   "source": [
    "n_run = 5 #number of runs\n",
    "cros_val(model_l, X, price_train, n_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "regr_tree = DecisionTreeRegressor()\n",
    "regr_tree.fit(X, price_train)\n",
    "n_run = 5 #number of runs\n",
    "cros_val(regr_tree, X, price_train, n_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR (support vector regression):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_poly  = SVR(kernel='poly', C=1e3, degree=2)\n",
    "svr_model = svr_poly.fit(X, price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_run = 5 #number of runs\n",
    "cros_val(svr_model, X, price_train, n_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
